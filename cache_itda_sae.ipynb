{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import OrderedDict\n",
    "from datasets import load_dataset\n",
    "from more_itertools import chunked\n",
    "from itda import ITDAConfig, ITDA\n",
    "from tqdm.auto import tqdm\n",
    "import numpy, torch\n",
    "import json, os\n",
    "os.makedirs(\"dataset\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a79c6e157044ec8f72e6304daaaa4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc48ab086be41db8c3bace2a323da44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import FluxPipeline\n",
    "\n",
    "pipe = FluxPipeline.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.1-schnell\", torch_dtype=torch.bfloat16, device_map=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f22ea997980>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nf4 = np.asarray(\n",
    "    [\n",
    "        -1.0,\n",
    "        -0.6961928009986877,\n",
    "        -0.5250730514526367,\n",
    "        -0.39491748809814453,\n",
    "        -0.28444138169288635,\n",
    "        -0.18477343022823334,\n",
    "        -0.09105003625154495,\n",
    "        0.0,\n",
    "        0.07958029955625534,\n",
    "        0.16093020141124725,\n",
    "        0.24611230194568634,\n",
    "        0.33791524171829224,\n",
    "        0.44070982933044434,\n",
    "        0.5626170039176941,\n",
    "        0.7229568362236023,\n",
    "        1.0,\n",
    "    ]\n",
    ")\n",
    "image_max = 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_dataset = load_dataset(\"opendiffusionai/cc12m-cleaned\")\n",
    "prompts_iterator = prompts_dataset[\"train\"][\"caption_llava_short\"]\n",
    "guidance_scale = 3.5\n",
    "num_inference_steps = 1\n",
    "batch_size = 32\n",
    "width = 256\n",
    "height = 256\n",
    "d_model = 3072\n",
    "itda_config = ITDAConfig(\n",
    "    d_model=d_model,\n",
    "    target_l0=64,\n",
    "    loss_threshold=0.6,\n",
    "    add_error=True,\n",
    "    fvu_loss=True,\n",
    "    subtract_mean=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8531902"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompts_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize = True\n",
    "device = torch.device(\"cuda:0\")\n",
    "itda = ITDA(itda_config, dtype=torch.bfloat16, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from loguru import logger\n",
    "import shutil\n",
    "import orbax.checkpoint as ocp\n",
    "from pathlib import Path\n",
    "import jax\n",
    "import os\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "\n",
    "\n",
    "def restore_array(path):\n",
    "    with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "        checkpointer = ocp.PyTreeCheckpointer()\n",
    "        vals_meta = checkpointer.metadata(path)\n",
    "        sharding = jax.sharding.SingleDeviceSharding(jax.devices(\"cpu\")[0])\n",
    "        restore_args = ocp.checkpoint_utils.construct_restore_args(\n",
    "            vals_meta,\n",
    "            sharding_tree=jax.tree.map(lambda _: sharding, vals_meta)\n",
    "        )\n",
    "        restored_vals = checkpointer.restore(path, restore_args=restore_args)\n",
    "    return restored_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, hf_hub_download\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "def download_subdirectory(repo_id, subdir, local_dir, repo_type=\"model\"):\n",
    "    print(f\"Downloading {subdir} from {repo_id} to {local_dir}\")\n",
    "    # Initialize HfApi\n",
    "    api = HfApi()\n",
    "\n",
    "    # List all files in the repository\n",
    "    print(f\"Listing files in {repo_id}\")\n",
    "    all_files = api.list_repo_files(repo_id=repo_id, repo_type=repo_type)\n",
    "\n",
    "    # Filter files that belong to the target subdirectory\n",
    "    target_files = [f for f in all_files if f.startswith(f\"{subdir}/\")]\n",
    "\n",
    "    print(f\"Found {len(target_files)} files in {subdir}\")\n",
    "    # Create local directory if it doesn't exist\n",
    "    os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "    # Download each file individually\n",
    "    for file in tqdm(target_files):\n",
    "        print(f\"Downloading {file}\")\n",
    "        hf_hub_download(\n",
    "            repo_id=repo_id,\n",
    "            filename=file,\n",
    "            repo_type=repo_type,\n",
    "            local_dir=local_dir,\n",
    "            local_dir_use_symlinks=False  # Save actual files instead of symlinks\n",
    "        )\n",
    "    print(f\"Downloaded {len(target_files)} files to {local_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dpath = download_subdirectory(\"nev/flux1-saes\", \"sae_double_l18_img\", \"flux1-saes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-03-08 05:37:50,105:jax._src.xla_bridge:966: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "WARNING:jax._src.xla_bridge:An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "layer = 18\n",
    "sae_mid = restore_array(os.path.abspath(\n",
    "    f\"flux1-saes/sae_double_l{layer}_img/30000/default\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_means = sae_mid[\"info\"][\"feature_means\"]\n",
    "fs_sq_means = sae_mid[\"info\"][\"feature_square_means\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = np.sqrt(np.maximum(fs_sq_means - np.square(fs_means), 1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm = sae_mid[\"info\"][\"whitening_matrix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dec_in = (sae_mid[\"sae_params\"][\"W_dec\"] / stds) @ wm.T\n",
    "w_dec_out = (sae_mid[\"sae_params\"][\"W_dec\"] * stds) @ wm.T\n",
    "\n",
    "w_dec_in = torch.tensor(w_dec_in)\n",
    "w_dec_out = torch.tensor(w_dec_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_in = sae_mid[\"sae_params\"][\"b_post\"] - sae_mid[\"sae_params\"][\"b_pre\"]\n",
    "bias_out = sae_mid[\"sae_params\"][\"b_post\"]\n",
    "bias_in = (fs_means + stds * bias_in) @ wm.T\n",
    "bias_out = (fs_means + stds * bias_out) @ wm.T\n",
    "# x = x @ wm\n",
    "# x = x - means\n",
    "# x = x / stds\n",
    "# x = x + bias_in\n",
    "# x = x @ w_dec\n",
    "# x = acts(x)\n",
    "# x = x @ w_enc\n",
    "# x = x + bias_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2610894/1534769764.py:2: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  w_dec_in = w_dec_in / np.linalg.norm(w_dec_in, axis=1, keepdims=True)\n",
      "/tmp/ipykernel_2610894/1534769764.py:3: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  w_dec_out = w_dec_out / np.linalg.norm(w_dec_out, axis=1, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "# w_dec = w_dec / np.linalg.norm(w_dec, axis=1, keepdims=True)\n",
    "w_dec_in = w_dec_in / np.linalg.norm(w_dec_in, axis=1, keepdims=True)\n",
    "w_dec_out = w_dec_out / np.linalg.norm(w_dec_out, axis=1, keepdims=True)\n",
    "itda.xs.data = w_dec_in\n",
    "itda.ys.data = w_dec_out\n",
    "\n",
    "itda.dictionary_size = w_dec_in.shape[0]\n",
    "\n",
    "itda.mean_x.data = torch.tensor(bias_in)\n",
    "itda.mean_y.data = torch.tensor(bias_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "itda.config.preprocessing_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "itda = itda.to(device)\n",
    "itda = itda.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caching_utils import save_itda_outputs\n",
    "from scored_storage import ScoredStorage\n",
    "from pathlib import Path\n",
    "\n",
    "feature_acts = ScoredStorage(\n",
    "    Path(\"itda_data_saes\") / \"feature_acts.db\",\n",
    "    3, 1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = Path(\"images_itda_saes\")\n",
    "image_activations_dir = Path(\"image_activations_itda_saes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe38befe87a74ad48bd3fa8ebc70aa0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from itda import grad_pursuit, decoder_impl\n",
    "\n",
    "\n",
    "for i, prompts in enumerate(chunked((bar := tqdm(prompts_iterator[10000:11000])), batch_size)):\n",
    "    with torch.inference_mode():\n",
    "        for m in pipe.transformer.modules():\n",
    "            m._forward_hooks = OrderedDict()\n",
    "        text_outputs = {}\n",
    "        image_outputs = {}\n",
    "        timestep = 0\n",
    "\n",
    "        def save_hook(self, input, output):\n",
    "            text_outputs[timestep] = output[0]\n",
    "            image_outputs[timestep] = output[1]\n",
    "        pipe.transformer.transformer_blocks[18].register_forward_hook(\n",
    "            save_hook)\n",
    "        height = 256\n",
    "        width = 256\n",
    "\n",
    "        def callback_on_step_end(self, i, t, kwargs):\n",
    "            global timestep\n",
    "            timestep = i\n",
    "            return {}\n",
    "        pipe.set_progress_bar_config(disable=True)\n",
    "        with torch.inference_mode():\n",
    "            latents = pipe(\n",
    "                prompts,\n",
    "                height=height,\n",
    "                width=width,\n",
    "                guidance_scale=guidance_scale,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                max_sequence_length=512,\n",
    "                generator=torch.Generator(\"cpu\").manual_seed(0),\n",
    "                return_dict=False,\n",
    "                callback_on_step_end=callback_on_step_end,\n",
    "                output_type=\"latent\",\n",
    "            )[0]\n",
    "        latents_reshaped = pipe._unpack_latents(\n",
    "            latents, height, width, pipe.vae_scale_factor)\n",
    "        latents_to_be_compressed = latents_reshaped.cpu().float().numpy()\n",
    "\n",
    "        x = image_outputs[0].to(torch.bfloat16).to(device)\n",
    "        x = x.reshape(-1, d_model)\n",
    "        x = x.to(device)\n",
    "        # x_ = x\n",
    "        # mat_ = (\n",
    "        #     torch.tensor(wm).to(torch.bfloat16).to(device)\n",
    "        #     / torch.tensor(stds).to(torch.bfloat16).to(device)\n",
    "        # )\n",
    "        # mat = (\n",
    "        #     torch.tensor(wm).to(torch.bfloat16).to(device)\n",
    "        #     * torch.tensor(stds).to(torch.bfloat16).to(device)\n",
    "        # )\n",
    "        # # x = x @ mat\n",
    "\n",
    "        # # x = x - torch.tensor(fs_means).to(torch.bfloat16).to(device)\n",
    "        # # x = x\n",
    "\n",
    "        # wd = torch.tensor(sae_mid[\"sae_params\"][\"W_dec\"]).to(\n",
    "        #     device).to(torch.bfloat16)\n",
    "        # # wd = wd * torch.tensor(stds).to(torch.bfloat16).to(device)\n",
    "        # # wd = wd / wd.norm(dim=1, keepdim=True)\n",
    "        # # wd = wd @ mat.T\n",
    "        # # wd = w_dec\n",
    "\n",
    "        # # # wd = torch.randn_like(w_dec)\n",
    "        # # wd = wd / wd.norm(dim=1, keepdim=True)\n",
    "\n",
    "        # wd_ = wd\n",
    "        # # x = x @ mat\n",
    "        # wd_ = wd_ @ mat_.T\n",
    "        # # print(wd.norm(dim=-1))\n",
    "        # wd_ = wd_ / wd_.norm(dim=1, keepdim=True)\n",
    "        # wd = wd @ mat.T\n",
    "\n",
    "        # weights, indices = grad_pursuit(x, wd_, 64)\n",
    "        # # x = x - torch.tensor(bias_in).to(torch.bfloat16).to(device)\n",
    "        # y_reconstructed = decoder_impl(indices, weights, wd)\n",
    "        # # y_reconstructed = y_reconstructed * \\\n",
    "        # #     torch.tensor(stds).to(torch.bfloat16).to(device)\n",
    "        # # # y_reconstructed = y_reconstructed + torch.tensor(fs_means).to(torch.bfloat16).to(device)\n",
    "        # # y_reconstructed = y_reconstructed @ torch.tensor(\n",
    "        # #     wm).to(torch.bfloat16).to(device).T\n",
    "\n",
    "        # x = x_\n",
    "\n",
    "        # y = x\n",
    "        # correlation = ((y - y.mean(axis=0)) * (y_reconstructed -\n",
    "        #                y_reconstructed.mean(axis=0))).mean(axis=0)\n",
    "        # var_explained = torch.nan_to_num(torch.square(correlation) / (\n",
    "        #     torch.var(y, axis=0) * torch.var(y_reconstructed, axis=0)\n",
    "        # )).mean().item()\n",
    "\n",
    "        out = itda(x, x)\n",
    "\n",
    "        weights, indices = out.weights, out.indices\n",
    "\n",
    "        weights, indices = (x @ itda.xs[:itda.dictionary_size].T\n",
    "                            ).topk(itda.config.target_l0, dim=-1)\n",
    "        weights = weights.float().cpu().numpy()\n",
    "        indices = indices.cpu().numpy()\n",
    "\n",
    "        weights = weights.reshape(\n",
    "            image_outputs[0].shape[0], image_outputs[0].shape[1], -1)\n",
    "        indices = indices.reshape(\n",
    "            image_outputs[0].shape[0], image_outputs[0].shape[1], -1)\n",
    "\n",
    "        var_explained = out.var_explained\n",
    "        bar.set_postfix(ve=float(var_explained))\n",
    "\n",
    "        save_itda_outputs(\n",
    "            weights, indices, prompts=prompts, images=latents_to_be_compressed, feature_acts=feature_acts, save_image_activations=True, step=i,\n",
    "            images_dir=images_dir, image_activations_dir=image_activations_dir\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1387, device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.var_explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itda.xs - itda_clone.xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mweights\u001b[49m\u001b[38;5;241m.\u001b[39mshape, indices\u001b[38;5;241m.\u001b[39mshape, latents_to_be_compressed\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "weights.shape, indices.shape, latents_to_be_compressed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "bins = 1000\n",
    "with torch.inference_mode():\n",
    "    xs = itda.xs[:itda.dictionary_size]\n",
    "    pp = xs[torch.randperm(len(xs))[:100]] @ xs.T\n",
    "    mn = pp.min().item()\n",
    "    mx = pp.max().item()\n",
    "    hist = torch.histc(pp, bins=bins,) / pp.numel()\n",
    "# plt.plot(np.linspace(mn, mx, bins), hist.cpu().numpy())\n",
    "plt.scatter(np.log2(np.abs(np.linspace(mn, mx, bins))), hist.cpu().numpy())\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.auto import trange\n",
    "# @torch.compile#(mode=\"reduce-overhead\")\n",
    "# def step(xs):\n",
    "#     prods = (torch.nn.functional.cosine_similarity(xs[:, None, :], xs[None, :, :], dim=-1) - torch.eye(len(xs), device=xs.device, dtype=xs.dtype)).flatten()\n",
    "#     max_prod = prods.argmax().item()\n",
    "#     max_a = max_prod // len(xs)\n",
    "#     max_b = max_prod % len(xs)\n",
    "#     combined = xs[max_a] + xs[max_b]\n",
    "#     xs[max_a] = combined\n",
    "#     xs[max_b], xs[-1] = xs[-1], xs[max_b]\n",
    "#     xs = xs[:-1]\n",
    "#     return xs, max_prod > 0.5\n",
    "# with torch.inference_mode():\n",
    "#     xs = itda.xs[:itda.dictionary_size].clone()\n",
    "#     # for i in (bar := trange(5000)):\n",
    "#     for i in trange(5000):\n",
    "#         xs, stop = step(xs)\n",
    "#         if stop:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "uv sync\n",
    "uv pip install \\\n",
    "    --extra-index-url=https://pypi.nvidia.com \\\n",
    "    \"cudf-cu12==25.2.*\" \"cuml-cu12==25.2.*\" --prerelease=allow --index-strategy unsafe-best-match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.2 s, sys: 213 ms, total: 24.4 s\n",
      "Wall time: 24.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KMeans</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>KMeans()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KMeans()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0141,  0.0201, -0.0138,  ...,  0.0184,  0.0069,  0.0067],\n",
       "        [-0.0096, -0.0100, -0.0234,  ...,  0.0041,  0.0097, -0.0040],\n",
       "        [ 0.0420,  0.0256,  0.0227,  ...,  0.0082, -0.0022, -0.0042],\n",
       "        ...,\n",
       "        [ 0.0162,  0.0035, -0.0098,  ...,  0.0096,  0.0286,  0.0162],\n",
       "        [-0.0085,  0.0152, -0.0327,  ..., -0.0248,  0.0037, -0.0085],\n",
       "        [-0.0117, -0.0345, -0.0163,  ..., -0.0020,  0.0023,  0.0173]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
